# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: mmcelebahq
  - override /model: ipadapter
  - override /callbacks: default
  - override /trainer: gpu

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["celebahq", "ipadapter_sample_text_mask_loss"]

seed: 42

model:
  diffusion_schedule:
    _target_: diffusers.PNDMScheduler
    beta_end: 0.012
    beta_schedule: scaled_linear
    beta_start: 0.00085
    num_train_timesteps: 1000
    set_alpha_to_one: false
    skip_prk_steps: true
    steps_offset: 1
    trained_betas: null
    # clip_sample: false
    prediction_type: sample
  face_seg:
    _target_: facer.face_parsing.FaRLFaceParser
    conf_name: farl/celebm/448
    model_path: checkpoints/face/face_parsing.farl.celebm.main_ema_181500_jit.pt
  froze_components: ["vae","text_encoder","unet","image_encoder","face_seg","net_clip"]
  loss_type: ["mask_loss","text_loss"]

logger:
  wandb:
    tags: ${tags}
    group: "ipadapter_sample_text_mask_loss"
  aim:
    experiment: "ipadapter_sample_text_mask_loss"
